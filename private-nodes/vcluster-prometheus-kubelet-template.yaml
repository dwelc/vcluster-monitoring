# vCluster Prometheus for Private Node Metrics
# Scrapes kubelet/cadvisor metrics directly from private nodes using their InternalIP,
# plus API server metrics, and remote-writes them to a central Prometheus via
# internal load balancer.
#
# This approach uses direct IP scraping (like kube-prometheus-stack) which:
#   - Requires VPN node-to-node enabled OR all nodes on the same network
#   - Avoids the InternalDNS issue that affects API proxy approach
#   - Is simpler and has fewer failure points
#
# Prerequisites:
#   1. Central Prometheus exposed via internal LoadBalancer
#   2. enableRemoteWriteReceiver: true on central Prometheus
#   3. VPN node-to-node enabled (privateNodes.vpn.nodeToNode.enabled: true)
#      OR all private nodes on the same network
#
# Usage:
#   1. Update PROMETHEUS_REMOTE_WRITE_URL to your internal LB endpoint
#   2. Update VCLUSTER_NAME to identify this vcluster
#   3. kubectl apply -f vcluster-prometheus-kubelet.yaml (inside vcluster context)
#
---
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
  # Need to discover nodes
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list", "watch"]
  # Direct kubelet metrics access (no proxy needed)
  - apiGroups: [""]
    resources: ["nodes/metrics"]
    verbs: ["get"]
  # For service discovery (if you want to scrape other things later)
  - apiGroups: [""]
    resources: ["services", "endpoints", "pods"]
    verbs: ["get", "list", "watch"]
  # Need to access /metrics endpoint on API server
  - nonResourceURLs: ["/metrics"]
    verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: monitoring
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 30s
      evaluation_interval: 30s
      external_labels:
        vcluster: "VCLUSTER_NAME"

    # Remote write to central Prometheus via internal load balancer
    remote_write:
      - url: "http://PROMETHEUS_REMOTE_WRITE_URL/api/v1/write"
        # Optional: Add basic auth if your Prometheus requires it
        # basic_auth:
        #   username: prometheus
        #   password_file: /etc/prometheus/password

    scrape_configs:
      # Scrape kubelet metrics directly via node InternalIP
      - job_name: 'kubelet'
        kubernetes_sd_configs:
          - role: node
        scheme: https
        tls_config:
          insecure_skip_verify: true  # kubelet uses self-signed certs
        authorization:
          credentials_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          # Use node's InternalIP directly (requires VPN node-to-node or same network)
          - source_labels: [__meta_kubernetes_node_address_InternalIP]
            target_label: __address__
            replacement: ${1}:10250
          # Keep node labels
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          # Add node name as label
          - source_labels: [__meta_kubernetes_node_name]
            target_label: node

      # Scrape cAdvisor metrics (container CPU/memory) directly via node InternalIP
      - job_name: 'kubelet-cadvisor'
        kubernetes_sd_configs:
          - role: node
        scheme: https
        tls_config:
          insecure_skip_verify: true  # kubelet uses self-signed certs
        authorization:
          credentials_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        metrics_path: /metrics/cadvisor
        relabel_configs:
          # Use node's InternalIP directly
          - source_labels: [__meta_kubernetes_node_address_InternalIP]
            target_label: __address__
            replacement: ${1}:10250
          # Keep node labels
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          # Add node name as label
          - source_labels: [__meta_kubernetes_node_name]
            target_label: node

      # Scrape kubelet resource metrics (newer endpoint, includes pod resource usage)
      - job_name: 'kubelet-resource'
        kubernetes_sd_configs:
          - role: node
        scheme: https
        tls_config:
          insecure_skip_verify: true  # kubelet uses self-signed certs
        authorization:
          credentials_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        metrics_path: /metrics/resource
        relabel_configs:
          # Use node's InternalIP directly
          - source_labels: [__meta_kubernetes_node_address_InternalIP]
            target_label: __address__
            replacement: ${1}:10250
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - source_labels: [__meta_kubernetes_node_name]
            target_label: node

      # Scrape vCluster API server metrics
      - job_name: 'apiserver'
        kubernetes_sd_configs:
          - role: endpoints
            namespaces:
              names: ['default']
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        authorization:
          credentials_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          # Only keep the kubernetes API server endpoint
          - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
            action: keep
            regex: kubernetes;https
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app: prometheus
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      securityContext:
        fsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
      containers:
        - name: prometheus
          image: prom/prometheus:v2.48.0
          args:
            - '--config.file=/etc/prometheus/prometheus.yml'
            - '--storage.tsdb.path=/prometheus'
            # Minimal retention - we're just buffering for remote-write
            - '--storage.tsdb.retention.time=15m'
            - '--storage.tsdb.retention.size=256MB'
            - '--web.enable-lifecycle'
            # Enable admin API for debugging
            - '--web.enable-admin-api'
          ports:
            - containerPort: 9090
              name: http
          resources:
            requests:
              cpu: 100m
              memory: 256Mi
            limits:
              cpu: 500m
              memory: 512Mi
          volumeMounts:
            - name: config
              mountPath: /etc/prometheus
            - name: storage
              mountPath: /prometheus
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9090
            initialDelaySeconds: 30
            periodSeconds: 15
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9090
            initialDelaySeconds: 5
            periodSeconds: 5
      volumes:
        - name: config
          configMap:
            name: prometheus-config
        - name: storage
          emptyDir:
            sizeLimit: 512Mi
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
spec:
  selector:
    app: prometheus
  ports:
    - port: 9090
      targetPort: 9090
      name: http
